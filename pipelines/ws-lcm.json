{
    "4": {
        "inputs": {
            "ckpt_name": "sd_xl_base_1.0.safetensors"
        },
        "class_type": "CheckpointLoaderSimple"
    },
    "6": {
        "inputs": {
            "text": "Oil painting of a nun, by Vincent Van Gogh, by Pablo Picasso",
            "clip": [
                "118",
                0
            ]
        },
        "class_type": "CLIPTextEncode"
    },
    "7": {
        "inputs": {
            "text": "text, watermark, frames, border, ugly, tiling, poorly drawn hands, poorly drawn feet, poorly drawn face, out of frame, extra limbs, disfigured, deformed, body out of frame, bad anatomy, watermark, signature, cut off, low contrast, underexposed, overexposed, bad art, beginner, amateur, distorted face",
            "clip": [
                "118",
                0
            ]
        },
        "class_type": "CLIPTextEncode"
    },
    "17": {
        "inputs": {
            "samples": [
                "120",
                0
            ],
            "vae": [
                "4",
                2
            ]
        },
        "class_type": "VAEDecode"
    },
    "49": {
        "inputs": {
            "control_net_name": "control-LoRAs-rank256/control-lora-depth-rank256.safetensors"
        },
        "class_type": "ControlNetLoader"
    },
    "50": {
        "inputs": {
            "strength": 1,
            "start_percent": 0,
            "end_percent": 1,
            "positive": [
                "6",
                0
            ],
            "negative": [
                "7",
                0
            ],
            "control_net": [
                "49",
                0
            ],
            "image": [
                "110",
                0
            ]
        },
        "class_type": "ControlNetApplyAdvanced"
    },
    "75": {
        "inputs": {
            "images": [
                "78",
                0
            ]
        },
        "class_type": "PreviewImage"
    },
    "76": {
        "inputs": {
            "pixels": [
                "78",
                0
            ],
            "vae": [
                "4",
                2
            ]
        },
        "class_type": "VAEEncode"
    },
    "77": {
        "inputs": {
            "width": 1024,
            "height": 1024,
            "frequency": 0.5,
            "attenuation": 0.5,
            "noise_type": "grey",
            "seed": 640661861010977
        },
        "class_type": "Image Power Noise"
    },
    "78": {
        "inputs": {
            "blend_percentage": 0.5,
            "image_a": [
                "79",
                0
            ],
            "image_b": [
                "77",
                0
            ]
        },
        "class_type": "Image Blend"
    },
    "79": {
        "inputs": {
            "mode": "resize",
            "supersample": "true",
            "resampling": "lanczos",
            "rescale_factor": 2,
            "resize_width": 1024,
            "resize_height": 1024,
            "image": [
                "122",
                0
            ]
        },
        "class_type": "Image Resize"
    },
    "108": {
        "inputs": {
            "images": [
                "122",
                0
            ]
        },
        "class_type": "PreviewImage"
    },
    "110": {
        "inputs": {
            "a": 6.28,
            "bg_threshold": 0,
            "resolution": 1024,
            "image": [
                "79",
                0
            ]
        },
        "class_type": "MiDaS-DepthMapPreprocessor"
    },
    "112": {
        "inputs": {
            "images": [
                "110",
                0
            ]
        },
        "class_type": "PreviewImage"
    },
    "114": {
        "inputs": {
            "lora_name": "pytorch_lora_weights.safetensors",
            "strength_model": 1,
            "strength_clip": 1,
            "model": [
                "4",
                0
            ],
            "clip": [
                "4",
                1
            ]
        },
        "class_type": "LoraLoader"
    },
    "115": {
        "inputs": {
            "sampling": "lcm",
            "zsnr": false,
            "model": [
                "114",
                0
            ]
        },
        "class_type": "ModelSamplingDiscrete"
    },
    "118": {
        "inputs": {
            "stop_at_clip_layer": -1,
            "clip": [
                "114",
                1
            ]
        },
        "class_type": "CLIPSetLastLayer"
    },
    "120": {
        "inputs": {
            "seed": 0,
            "steps": 4,
            "cfg": 1.6,
            "sampler_name": "lcm",
            "scheduler": "sgm_uniform",
            "denoise": 1,
            "model": [
                "115",
                0
            ],
            "positive": [
                "132",
                0
            ],
            "negative": [
                "132",
                1
            ],
            "latent_image": [
                "76",
                0
            ]
        },
        "class_type": "KSampler"
    },
    "122": {
        "inputs": {
            "image": ""
        },
        "class_type": "ETN_LoadImageBase64"
    },
    "123": {
        "inputs": {
            "images": [
                "17",
                0
            ]
        },
        "class_type": "ETN_SendImageWebSocket"
    },
    "131": {
        "inputs": {
            "control_net_name": "controlnet-openpose-sdxl-1.0/control-lora-openposeXL2-rank256.safetensors"
        },
        "class_type": "ControlNetLoader"
    },
    "132": {
        "inputs": {
            "strength": 1,
            "start_percent": 0,
            "end_percent": 1,
            "positive": [
                "50",
                0
            ],
            "negative": [
                "50",
                1
            ],
            "control_net": [
                "131",
                0
            ],
            "image": [
                "136",
                0
            ]
        },
        "class_type": "ControlNetApplyAdvanced"
    },
    "136": {
        "inputs": {
            "detect_hand": "enable",
            "detect_body": "enable",
            "detect_face": "enable",
            "resolution": 512,
            "image": [
                "79",
                0
            ]
        },
        "class_type": "OpenposePreprocessor"
    }
}